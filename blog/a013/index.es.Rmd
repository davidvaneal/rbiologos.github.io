---
title: Inferencia estadística
author: David Vanegas
date: '2021-10-12'
image: https://i.ibb.co/YfSz6TZ/ES.png
slug: []
categories:
  - R
  - RStudio
tags:
  - Inferencia
  - Estadística
  - P valor
  - Hipótesis
  - Parámetros
  - Errores
---

Se llama inferencia estadística a la rama de la Estadística encargada de hacer deducciones, es decir, inferir propiedades, conclusiones y tendencias, a partir de una muestra del conjunto. Su papel es interpretar, hacer proyecciones y comparaciones. 

Ahhhh bueno, te me cuidas, pero ¿qué? ¿cómo se come? ¿qué con eso?

<center>
![](https://i.ibb.co/st3rh5p/ok.gif){width="350"}
</center><br>

Pues, la estadística inferencial emplea usualmente mecanismos que nos permiten llevar a cabo dichas deducciones, tales como pruebas de estimación puntual (o de intervalos de confianza), pruebas de hipótesis, pruebas paramétricas (como de media, de diferencia de medias, proporciones, etc) y no paramétricas (como la prueba del chi-cuadrado, etc). También le son útiles los análisis de correlación y de regresión, las series cronológicas, el análisis de varianza, entre otros.

Su objetivo es extraer conclusiones de utilidad sobre el total de las observaciones posibles basándose en la información obtenida. Los dos tipos de problemas que resuelven las técnicas estadísticas son: estimación y contraste de hipótesis. En ambos casos se trata de generalizar la información obtenida en una muestra a una población. Estas técnicas exigen que la muestra sea aleatoria.

Bien, entonces aprendamos sobre algunas consideraciones y métodos que debemos tener en cuenta en nuestros estudios

<center>
![](https://i.ibb.co/rks53Tm/Wubba-lubba-dub-dub.gif){width="350"}
</center><br>

## Estimación de parámetros

En general, de las variables experimentales u observacionales no conocemos la función densidad de probabilidad. Podemos conocer la familia de distribución (normal, binomial,...) pero no los parámetros. Para calcularlos necesitaríamos tener todos los posibles valores de la variable, lo que no suele ser posible.

La inferencia estadística trata de cómo obtener información (inferir) sobre los parámetros a partir de subconjuntos de valores (muestras) de la variable. Evidentemente, habrá una distribución muestral para cada estadístico, no sólo para la media, y en consecuencia un error típico para cada estadístico.

Veamos un ejemplo que podemos tener en cuenta, queremos estudiar cuál es la altura media de los árboles en cierta ciudad de Colombia. La variable objeto de estudio es la altura de los árboles en cierta ciudad de Colombia, mientras que, el parámetro es la altura media de los árboles de esa ciudad. Entonces, si para cada muestra posible calculamos la media muestral, obtenemos un valor distinto, habrá por tanto una ***función densidad de probabilidad***, llamada distribución muestral de medias. 

Así, de lo anterior concluimos que los estimadores son estadísticos que deben, obligatoriamente, tomar valores posibles de los datos que estamos estudiando.

Ahora bien, no es suficiente solo con que tome valores que estén dentro del rango de datos. Normalmente se le exigen ciertas propiedades para que tengamos ciertas garantías. Puede darse el caso de que ciertos estimadores cumplan con la condición de ser estimadores, pero si estiman mal, será calificados como malos estimadores. Para mayor info pueden leer más en este sitio [Estadística Teórica: Estimadores](https://www.estadistica.net/Algoritmos2/estimadores.pdf)

<center>
![](https://i.ibb.co/MpY8wZt/MF.gif){width="350"}
</center><br>

## Intérvalos de confianza

Un intervalo de confianza es una técnica de estimación utilizada en inferencia estadística que permite acotar un par o varios pares de valores, dentro de los cuales se encontrará la estimación puntual buscada (con una determinada probabilidad).

Un intervalo de confianza nos va a permitir calcular dos valores alrededor de una media muestral (uno superior y otro inferior). Estos valores van a acotar un rango dentro del cual, con una determinada probabilidad, se va a localizar el parámetro poblacional.

Conocer el verdadero poblacional, por lo general, suele ser algo muy complicado. Pensemos en una población de mariposas en una región. ¿Podríamos saber el vuelo medio por mariposa de esa población? En principio sí. Simplemente tendríamos que hacer varios registros y calcular la media. Sin embargo, seguir ese proceso sería tremendamente laborioso y complicaría bastante el estudio.

<center>
![](https://i.ibb.co/tJ9wLkX/vacation.gif){width="350"}
</center><br>

Calma, calma cerebrito, en conclusión, el intervalo de confianza no sirve para dar una estimación puntual del parámetro poblacional, nos va a servir para hacernos una idea aproximada de cuál podría ser el verdadero de este. Nos permite acotar entre dos valores en dónde se encontrará la media de la población.

El cálculo de un intervalo de confianza depende principalmente de los siguientes factores:

- Tamaño de la muestra seleccionada: Dependiendo de la cantidad de datos que se hayan utilizado para calcular el valor muestral, este se acercará más o menos al verdadero parámetro poblacional.
- Nivel de confianza: Nos va a informar en qué porcentaje de casos nuestra estimación acierta. Los niveles habituales son el 95% y el 99%.
- Margen de error de nuestra estimación: Este se denomina como alfa y nos informa de la probabilidad que existe de que el valor poblacional esté fuera de nuestro intervalo.
- Lo estimado en la muestra (media, varianza, diferencia de medias…): De esto va a depender el estadístico para el cálculo del intervalo.

## Pruebas de hipótesis

Una hipótesis se define como una afirmación transitoria que debe ser sometida a prueba. La inferencia estadística propone un procedimiento para llevar a cabo la prueba de las hipótesis. Propone, primero, enunciarlas formalmente y luego contrastarlas con la evidencia de los datos. Son los datos, entonces, con su coro de características, los que dirán si una hipótesis es falsa o verdadera.

<center>
![](https://i.ibb.co/DC99GgQ/false.gif){width="350"}
</center><br>

Los investigadores se interesan en dos tipos de hipótesis: de investigación y estadísticas. La primera es una conjetura que motivó la investigación y la segunda son establecidas o enunciadas de tal manera que puedan ser contrastadas por medio de pruebas estadísticas adecuadas. Una hipótesis estadística es una proposición o supuesto sobre los parámetros de una o más poblaciones

Ahora, si queremos decidir entre dos hipótesis que afectan a un cierto parámetro de la población, a partir de la información de la muestra usaremos el contraste de hipótesis, cuando optemos por una de estas dos hipótesis, hemos de conocer una medida del error cometido, es decir, cuantas veces de cada cien nos equivocamos.

Para realizar tan delicada operación debemos utilizar el instrumento apropiado: le llamaremos estadístico de prueba, el que podremos calcular con los datos de nuestra muestra. Para ello debemos tener en cuenta los siguientes pasos:

<center>
![](https://i.ibb.co/9cMVKff/defies.gif){width="350"}
</center><br>

***Plantear hipótesis***

En primer lugar, debemos plantear la hipótesis en términos estadísticos, entonces veremos cómo se escribirían las hipótesis que queremos contrastar:

- ***H0*** conocida como _hipótesis nula_. Esta hipótesis formalmente plantea que los valores comparados son iguales.

- ***H1*** conocida como _hipótesis alternativa_. Esta hipótesis plantea que los valores comparados son distintos.

<center>
![](https://i.ibb.co/tctZzFf/twins.gif){width="350"}
</center><br>

***Nivel de significación***

El nivel de significación es la probabilidad de que la diferencia observada se deba al azar. Interesa que esta probabilidad sea pequeña, por eso, en la práctica se utilizan valores iguales o inferiores a ***0.05***. El valor más usado es 0.05 pero también puede ser 0.04, 0.02, 0.01, etc. Al nivel de significación se le identifica con la letra griega alfa _(α)_.

Cabe aclarar que cuando usamos los datos de una muestra para tomar decisiones acerca de un parámetro, existe el riesgo de llegar a una conclusión incorrecta. De hecho se pueden presentar dos tipos diferentes de error cuando se aplica la metodología de la prueba de hipótesis.

<center>
![](https://i.ibb.co/2hV0CjD/error.gif){width="350"}
</center><br>

***Error Tipo I***

Si rechazamos la hipótesis nula cuando es verdadera, podemos cometemos un error de tipo I. La probabilidad de cometer un error de tipo I es _α_, que es el nivel de significancia que establecemos para nuestra prueba de hipótesis. Un _α_ de 0.05 indica que estamos dispuestos a aceptar una probabilidad de 5% de estar equivocados al rechazar la hipótesis nula. Para reducir este riesgo, debemos utilizar un valor menor para _α_. Sin embargo, usar un valor menor para alfa significa que tendremos menos probabilidad de detectar una diferencia si esta realmente existe.

***Error Tipo II***

Cuando la hipótesis nula es falsa y no la rechazamos, cometemos un error de tipo II. La probabilidad de cometer un error de tipo II es _β_, que depende de la potencia de la prueba. Podemos reducir el riesgo de cometer un error de tipo II al asegurarse de que la prueba tenga suficiente potencia. Para ello, debemos asegurar de que el tamaño de la muestra sea lo suficientemente grande como para detectar una diferencia práctica cuando esta realmente exista.

La probabilidad de rechazar la hipótesis nula cuando es falsa es igual a _1–β_. Este valor es la potencia de la prueba.

***P Valor***

Los valores de _p_ son comúnmente utilizados para probar (y descartar) una _H0_, cuanto menor sea el valor de _p_, menor es la probabilidad de que un conjunto de valores observados ocurra por casualidad. Un valor _p_ de ***0.05*** o menos suele entenderse en el sentido de que las observaciones son estadísticamente significativas y justifica los resultados de un estudio. Pero eso no es necesariamente cierto, se debe analizar con cuidado por parte de los investigadores por lo que hay que evitar sacar conclusiones científicas o tomar decisiones basadas solo en los valores de _p_.

<center>
![](https://i.ibb.co/VSKzwL7/travel.gif){width="350"}
</center><br>

Un valor _p_ de ***0.05***, no significa que hay una posibilidad del 95% que una determinada hipótesis es correcta. Más bien, significa que, si la _H0_ es verdadera, y todas las demás suposiciones hechas son válidas, hay una probabilidad del ***5%*** de obtener un resultado al menos tan extremo como el observado. Y un valor de p no puede indicar la importancia de un hallazgo; por ejemplo, un medicamento puede tener un efecto estadísticamente significativo en los niveles de glucosa en la sangre del paciente sin tener un efecto terapéutico, en este caso hay relevancia estadística pero el hallazgo clínico también es importante dado que dicho medicamento no es eficaz en el tratamiento de la diabetes.

En términos generales podemos conocer el comportamiento de la hipótesis en relación al valor _p_

- _p_ = 0.10, tenemos alguna evidencia que H0 no es verdadera.
- _p_ = 0.05, tenemos fuerte evidencia que H0 no es verdadera.
- _p_ = 0.01, tenemos muy fuerte evidencia que H0 no es verdadera.
- _p_ = 0.001, tenemos una extremadamente fuerte evidencia que H0 no es verdadera.

## Pruebas paramétricas

Las pruebas paramétricas asumen distribuciones estadísticas subyacentes a los datos. Por tanto, deben cumplirse algunas condiciones de validez, de modo que el resultado de la prueba paramétrica sea fiable. Por ejemplo, la prueba t de Student para dos muestras independientes será fiable solo si cada muestra se ajusta a una distribución normal y si las varianzas son homogéneas.

<center>
![](https://i.ibb.co/3sz6zck/excuse-me.gif){width="350"}
</center><br>

Las ventajas de las pruebas paramétricas son:

- Sensibles a rasgos de los datos recolectados
- Estimaciones probabilísticas más exactas
- Tienen una mayor eficiencia estadística
- Mayor poder estadístico

Las desventajas de las purebas paramétricas son:

- Más complicadas de calcular
- Solo se pueden aplicar si se cumplen sus supuestos

Algunos de los análisis más populares son:

|Análisis|Paramétrico|
|:-----|:-----|
|Describir un grupo|μ - σ2|
|Comparar un grupo a un valor|T Student de una muestra|
|Comparar medias en dos grupos|T Student de dos muestras|
|Comparar medias en dos grupos apareados|T Student apareada|
|Comparar medias en tres o más grupos|ANOVA|
|Correlación entre dos variables|Pearson (Lineal)|

## Pruebas No Paramétricas

Este tipo de pruebas no requieren que las muestras tengan una distrtibución conocida (por ejemplo, la distribución normal) por lo que también se les conoce como pruebas de distribución libre. Aunque el término no paramétrico suguiere que no se basan en un parámetro, existen pruebas no paramétricas que sí dependen de un parámetro, por ejemplo, la mediana.

<center>
![](https://i.ibb.co/hYsXwSw/free.gif){width="350"}
</center><br>

Las ventajas de las pruebas no paramétricas son:

- Las pruebas no paramétricas nos permiten analizar datos en escala nominal u ordinal
- Se pueden aplicar a una amplia variedad de situaciones
- Se pueden utilizar variables de nivel de medición nominal
- Son más fáciles de calcular

Las desventajas de las pruebas no paramétricas son:

- Su eficiencia estadística es menor
- Su poder estadístico es menor
- Desperdician información

Algunos de los análisis más populares son:

|Tamaño de la muestra|Tipo variable|Análisis|
|:-----|:-----|:-----|
|Una muestra|Cuantitativa - Cualitativa|Chi cuadrado - Binomial|
|Dos muestras|Independientes - Cuantitativas|U de Mann Whitney|
|   |Relacionadas - Cuantitativas|Wilcoxon|
|   |Relacionadas - Cualitativas|Mc Nemar|
|Más de dos muestras|Independientes - Cuantitativas|Kruskal Wallis|
|   |Relacionadas - Cuantitativas|Friedman|
|   |Relacionadas - Cualitativas|Q de Cochran|

## Resumen

Y buenooooo, seguimos aprendiendo cada post, más y más, algunas veces no tan divertidas como otras, pero siempre podremos aprender algo más que nos servirá en nuestros objetivos personales y profesionales

<center>
![](https://i.ibb.co/zfYRqq3/boss.gif){width="350"}
</center><br>

En este post pudimos aprender y entender sobre algunas bases estadísticas como los parámetros, intérvalos de confianza, pruebas de hipótesis y pruebas paramétricas y no paramétricas. Pero ten cuidado y no te confies unicamente en lo que podemos resumir acá, el mundo de la estadística es mucho más amplio y con bases matemáticas que no abordamos, así que los invitamos a leer un poco más, con el fin de entender más los procedimientos o técnicas que iremos abordando.

Y no siendo más...

¡¡¡HASTA LA PRÓXIMA!!!

<center>
![](https://i.ibb.co/F5n6gfH/middle.gif){width="350"}
</center><br>

## Bibliografía

- [Estadística inferencial](https://concepto.de/estadistica-inferencial/)

- [Significado de Estadística](https://www.significados.com/estadistica/)

- [Manual de R](https://fhernanb.github.io/Manual-de-R/normalidad.html)

- [Material docente de la Unidad de Bioestadística Clínica](http://www.hrc.es/bioest/M_docente.html#tema2)

- [Estimador](https://economipedia.com/definiciones/estimador.html)

- [Intervalo de confianza](https://economipedia.com/definiciones/intervalo-de-confianza.html)

- [La prueba de hipótesis](https://www.medwave.cl/link.cgi/Medwave/Series/MBE04/5066)

- [Pruebas de hipótesis](http://recursostic.educacion.es/descartes/web/materiales_didacticos/Muestreo_Inferencia_Estadistica/pruebas_hipotesis.html)

- [Pruebas de hipótesis](https://blogs.ugto.mx/enfermeriaenlinea/unidad-didactica-3-las-pruebas-de-hipotesis/)

- [¿Qué son los errores de tipo I y tipo II?](https://support.minitab.com/es-mx/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/type-i-and-type-ii-error/)

- [Estadística paramétrica y no paramétrica](https://www.rpubs.com/tonosan/param_no_param)

- [Pruebas paramétricas y no paramétricas](https://enviromigration.files.wordpress.com/2016/04/pruebas-paramc3a9tricas-y-no-parametricas.pdf)

## Más información 

Estos análisis se han realizado utilizando el software R (v.4.1.0) y Rstudio (v. 1.4.1717)

Recuerda que todos nuestros códigos están almacenados en [GitHub](https://github.com/RBiologos/Posts) 

<center>
![](https://i.ibb.co/DpKmR1k/github.png){width="350"}
</center>